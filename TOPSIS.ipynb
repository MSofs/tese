{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import joblib\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('variaveis.pkl', 'rb') as f:\n",
    "  X_train, Y_train, X_test, Y_teste = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('dataset.pkl', 'rb') as f:\n",
    "  df,target = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Q20__nota_português_2.ºperiodo  Q26__nota_mat_2.ºperiodo  \\\n",
      "0                               4.0                       4.0   \n",
      "1                               3.0                       3.0   \n",
      "2                               3.0                       4.0   \n",
      "3                               3.0                       4.0   \n",
      "4                               4.0                       4.0   \n",
      "..                              ...                       ...   \n",
      "840                             4.0                       2.0   \n",
      "841                             3.0                       3.0   \n",
      "842                             5.0                       5.0   \n",
      "843                             5.0                       5.0   \n",
      "844                             3.0                       3.0   \n",
      "\n",
      "     Q16_satisfação_com_notas_escolares  Q15_as_minhas_notas  \\\n",
      "0                                   4.0                  4.0   \n",
      "1                                   3.0                  3.0   \n",
      "2                                   4.0                  3.0   \n",
      "3                                   3.0                  2.0   \n",
      "4                                   5.0                  4.0   \n",
      "..                                  ...                  ...   \n",
      "840                                 3.0                  3.0   \n",
      "841                                 1.0                  1.0   \n",
      "842                                 4.0                  3.0   \n",
      "843                                 5.0                  3.0   \n",
      "844                                 4.0                  3.0   \n",
      "\n",
      "     envolvimento_scoretotal  \n",
      "0                       21.0  \n",
      "1                       23.0  \n",
      "2                       19.0  \n",
      "3                       20.0  \n",
      "4                       22.0  \n",
      "..                       ...  \n",
      "840                     20.0  \n",
      "841                     19.0  \n",
      "842                     24.0  \n",
      "843                     23.0  \n",
      "844                     18.0  \n",
      "\n",
      "[845 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0      1\n",
      "1      1\n",
      "2      1\n",
      "3      0\n",
      "4      3\n",
      "      ..\n",
      "840    1\n",
      "841    0\n",
      "842    3\n",
      "843    3\n",
      "844    1\n",
      "Name: aux, Length: 845, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Asus\\anaconda3\\envs\\Tese\\lib\\site-packages\\xgboost\\sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "c:\\Users\\Asus\\anaconda3\\envs\\Tese\\lib\\site-packages\\xgboost\\sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "c:\\Users\\Asus\\anaconda3\\envs\\Tese\\lib\\site-packages\\xgboost\\sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "c:\\Users\\Asus\\anaconda3\\envs\\Tese\\lib\\site-packages\\xgboost\\sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "c:\\Users\\Asus\\anaconda3\\envs\\Tese\\lib\\site-packages\\xgboost\\sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "c:\\Users\\Asus\\anaconda3\\envs\\Tese\\lib\\site-packages\\xgboost\\sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "c:\\Users\\Asus\\anaconda3\\envs\\Tese\\lib\\site-packages\\xgboost\\sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "c:\\Users\\Asus\\anaconda3\\envs\\Tese\\lib\\site-packages\\xgboost\\sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "c:\\Users\\Asus\\anaconda3\\envs\\Tese\\lib\\site-packages\\xgboost\\sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "c:\\Users\\Asus\\anaconda3\\envs\\Tese\\lib\\site-packages\\xgboost\\sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 1 1 3 2 1 2 1 3 3 0 1 2 2 1 0 0 2 2 1 3 0 2 0 2 1 2 0 0 2 1 0 2 0 2 0\n",
      " 2 2 2 3 1 2 0 2 2 2 2 1 2 3 0 3 2 2 2 3 1 3 1 3 3 2 3 0 1 3 0 2 3 3 1 2 2\n",
      " 1 3 2 0 3 3 1 1 1 3 1 1 2 1 3 2 3 3 1 3 3 2 0 1 3 2 2 2 1 2 0 2 2 0 0 1 0\n",
      " 0 0 0 1 1 2 0 0 2 3 2 2 0 3 2 1 0 1 1 1 3 3 3 2 2 3 1 0 1 1 1 0 0 0 3 3 1\n",
      " 3 0 2 2 2 1 2 3 2 1 1 2 1 1 0 1 1 2 0 2 3 0 0 3 1 3 1 2 2 2 1 2 0 1 1 3 1\n",
      " 1 2 0 1 3 1 0 2 1 2 1 2 2 3 1 3 3 1 1 3 2 0 2 1 1 1 3 1 3 1 1 3 1 2 0 3 2\n",
      " 3 0 3 1 1 1 1 2 0 0 1 1 0 3 3 3 1 1 1 0 1 0 3 1 1 0 0 0 3 1 2 1 1 1 1 0 0\n",
      " 3 1 1 1 1 0 1 1 1 3 0 2 0 3 3 1 3 1 0 1 0 0 3 1 2 3 3 2 3 1 3 1 0 0 3 3 2\n",
      " 3 0 3 3 1 1 2 3 3 2 2 3 1 2 1 1 1 1 2 2 1 1 1 3 0 3 0 3 1 2 2 2 3 1 3 0 2\n",
      " 0 1 0 1 0 3 0 2 0 0 0 0 1 1 0 1 0 2 3 0 1 2 0 0 0 0 1 0 2 0 2 0 1 0 1 1 0\n",
      " 2 3 1 1 0 1 0 1 0 3 0 0 0 0 0 3 0 1 0 0 1 1 0 0 0 2 2 2 0 3 1 0 1 1 0 1 3\n",
      " 2 2 0 3 0 3 3 2 3 2 0 1 2 1 2 2 0 3 2 3 1 3 1 3 2 2 3 1 0 0 3 0 3 2 1 1 0\n",
      " 1 0 2 2 0 2 2 0 0 0 3 0 2 2 2 2 2 3 2 0 0 3 0 0 1 0 1 3 0 1 0 2 3 0 2 3 3\n",
      " 1 2 3 2 3 3 0 0 3 3 0 0 0 1 0 0 1 1 0 0 1 0 0 0 2 2 2 2 0 2 2 0 0 3 2 2 2\n",
      " 2 0 2 3 1 2 1 1 2 2 2 0 3 2 1 3 3 1 2 3 0 0 1 0 0 0 0 2 1 3 2 0 1 0 0 2 3\n",
      " 3 3 3 0 1 0 0 3 1 2 3 2 3 3 2 1 2 3 2 3 3 3 3 3 2 1 1 0 3 3 2 2 0 1 2 3 3\n",
      " 3 3 2 3 2 3 1 3 2 3 1 2 0 1 3 2 3 3 3 2 1 3 3 1 3 1 2 0 3 1 2 3 3 2 3 3 3\n",
      " 3 1 1 2 3 3 3 0 2 2 0 3 3 2 3 1 2 2 1 3 3 3 3 3 3 3 2 0 3 3 2 2 2 1 0 2 2\n",
      " 0 0 3 1 0 2 2 3 1 3 0 3 3 3 1 2 3 2 1 2 2 2 0 2 2 3 3 3 1 1 0 3 0 1 1 2 0\n",
      " 2 2 2 2 0 2 2 3 3 2 2 2 2 2 2 2 2 0 3 2 2 0 3 0 3 0 1 0 2 1 0 2 0 3 0 2 2\n",
      " 1 3 3 3 2 0 3 2 0 1 2 0 3 0 2 3 0 2 2 2 2 0 0 2 0 0 2 2 2 2 3 2 0 3 2 3 2\n",
      " 2 2 0 2 2 3 2 0 2 3 3 3 3 2 0 3 3 3 0 0 3 0 0 3 2 1 2 1 0 1 0 2 0 0 2 0 0\n",
      " 2 2 2 0 3 1 2 0 0 0 2 1 2 1 0 2 2 0 1 3 0 0 0 0 2 0 2 0 3 3 1]\n"
     ]
    }
   ],
   "source": [
    "loaded_model = joblib.load('XGBoost.joblib')\n",
    "result = loaded_model.score(df, target)\n",
    "predictions = loaded_model.predict(df)\n",
    "#print(result)\n",
    "val_score= cross_val_score(loaded_model, df, target, cv = 10).mean()\n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9834319526627219\n"
     ]
    }
   ],
   "source": [
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9657002801120449\n"
     ]
    }
   ],
   "source": [
    "print(val_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_final= df \n",
    "dataset_final['Prev_Cluster']=predictions\n",
    "\n",
    "#import pickle\n",
    "\n",
    "#with open('datasetFinal.pkl', 'wb') as f:\n",
    "#    pickle.dump(dataset_final,f)\n",
    "\n",
    "#print(dataset_final.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_final.to_pickle('dataset_final.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Q20__nota_português_2.ºperiodo</th>\n",
       "      <th>Q26__nota_mat_2.ºperiodo</th>\n",
       "      <th>Q16_satisfação_com_notas_escolares</th>\n",
       "      <th>Q15_as_minhas_notas</th>\n",
       "      <th>envolvimento_scoretotal</th>\n",
       "      <th>Prev_Cluster</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>840</th>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>841</th>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>842</th>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>843</th>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>844</th>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>845 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Q20__nota_português_2.ºperiodo  Q26__nota_mat_2.ºperiodo  \\\n",
       "0                               4.0                       4.0   \n",
       "1                               3.0                       3.0   \n",
       "2                               3.0                       4.0   \n",
       "3                               3.0                       4.0   \n",
       "4                               4.0                       4.0   \n",
       "..                              ...                       ...   \n",
       "840                             4.0                       2.0   \n",
       "841                             3.0                       3.0   \n",
       "842                             5.0                       5.0   \n",
       "843                             5.0                       5.0   \n",
       "844                             3.0                       3.0   \n",
       "\n",
       "     Q16_satisfação_com_notas_escolares  Q15_as_minhas_notas  \\\n",
       "0                                   4.0                  4.0   \n",
       "1                                   3.0                  3.0   \n",
       "2                                   4.0                  3.0   \n",
       "3                                   3.0                  2.0   \n",
       "4                                   5.0                  4.0   \n",
       "..                                  ...                  ...   \n",
       "840                                 3.0                  3.0   \n",
       "841                                 1.0                  1.0   \n",
       "842                                 4.0                  3.0   \n",
       "843                                 5.0                  3.0   \n",
       "844                                 4.0                  3.0   \n",
       "\n",
       "     envolvimento_scoretotal  Prev_Cluster  \n",
       "0                       21.0             1  \n",
       "1                       23.0             1  \n",
       "2                       19.0             1  \n",
       "3                       20.0             1  \n",
       "4                       22.0             3  \n",
       "..                       ...           ...  \n",
       "840                     20.0             2  \n",
       "841                     19.0             0  \n",
       "842                     24.0             3  \n",
       "843                     23.0             3  \n",
       "844                     18.0             1  \n",
       "\n",
       "[845 rows x 6 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Step 1: Load the dataset\n",
    "# dataset_final\n",
    "\n",
    "# Step 2: Separate the features and the decision matrix\n",
    "features = dataset_final.values #features = dataset_final.iloc[:, 1:-1].values  # Assuming the features are in columns 1 to second-last\n",
    "#decision_matrix = dataset_final.iloc[:, -1].values  # Assuming the decision matrix is in the last column\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 4.  4.  4.  4. 21.  1.]\n",
      " [ 3.  3.  3.  3. 23.  1.]\n",
      " [ 3.  4.  4.  3. 19.  1.]\n",
      " ...\n",
      " [ 5.  5.  4.  3. 24.  3.]\n",
      " [ 5.  5.  5.  3. 23.  3.]\n",
      " [ 3.  3.  4.  3. 18.  1.]]\n"
     ]
    }
   ],
   "source": [
    "print(features)\n",
    "#print(decision_matrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.03672044 0.03603165 0.03519349 0.0458259  0.03646108 0.0182696 ]\n",
      " [0.02754033 0.02702374 0.02639512 0.03436943 0.03993356 0.0182696 ]\n",
      " [0.02754033 0.03603165 0.03519349 0.03436943 0.0329886  0.0182696 ]\n",
      " ...\n",
      " [0.04590054 0.04503956 0.03519349 0.03436943 0.04166981 0.05480881]\n",
      " [0.04590054 0.04503956 0.04399186 0.03436943 0.03993356 0.05480881]\n",
      " [0.02754033 0.02702374 0.03519349 0.03436943 0.03125236 0.0182696 ]]\n"
     ]
    }
   ],
   "source": [
    "# Step 3: Normalize the decision matrix\n",
    "normalized_matrix = features / np.sqrt(np.sum(features ** 2, axis=0))\n",
    "\n",
    "\n",
    "print(normalized_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: Define the weight vector (w) and impact vector (I)\n",
    "weights = [0.25, 0.25, 0.075, 0.15, 0.075, 0.2]   # Adjust the weights based on the importance of each feature\n",
    "impacts = ['-', '-', '-', '-', '-','-',]  # Adjust the impacts ('+' for maximization, '-' for minimization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.00918011 0.00900791 0.00263951 0.00687389 0.00273458 0.00365392]\n",
      " [0.00688508 0.00675593 0.00197963 0.00515541 0.00299502 0.00365392]\n",
      " [0.00688508 0.00900791 0.00263951 0.00515541 0.00247414 0.00365392]\n",
      " ...\n",
      " [0.01147514 0.01125989 0.00263951 0.00515541 0.00312524 0.01096176]\n",
      " [0.01147514 0.01125989 0.00329939 0.00515541 0.00299502 0.01096176]\n",
      " [0.00688508 0.00675593 0.00263951 0.00515541 0.00234393 0.00365392]]\n"
     ]
    }
   ],
   "source": [
    "# Step 5: Calculate the weighted normalized decision matrix\n",
    "weighted_normalized_matrix = normalized_matrix * weights\n",
    "\n",
    "print(weighted_normalized_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.00459005 0.00450396 0.00065988 0.00171847 0.00065109 0.        ]\n",
      "[0.01147514 0.01125989 0.00329939 0.00859236 0.00325545 0.01096176]\n"
     ]
    }
   ],
   "source": [
    "# Step 6: Determine the ideal and negative-ideal solutions\n",
    "ideal_solution = np.empty(normalized_matrix.shape[1])\n",
    "negative_ideal_solution = np.empty(normalized_matrix.shape[1])\n",
    "\n",
    "for i in range(normalized_matrix.shape[1]):\n",
    "    if impacts[i] == '+':\n",
    "        ideal_solution[i] = np.max(weighted_normalized_matrix[:, i])\n",
    "        negative_ideal_solution[i] = np.min(weighted_normalized_matrix[:, i])\n",
    "    else:\n",
    "        ideal_solution[i] = np.min(weighted_normalized_matrix[:, i])\n",
    "        negative_ideal_solution[i] = np.max(weighted_normalized_matrix[:, i])\n",
    "\n",
    "\n",
    "print(ideal_solution)\n",
    "print(negative_ideal_solution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.00946274 0.00653743 0.00761308 0.00688579 0.01414073 0.01069138\n",
      " 0.00940883 0.01082927 0.00665746 0.01541041 0.0152112  0.00587168\n",
      " 0.00890123 0.01009433 0.01064688 0.0078107  0.00341434 0.00509359\n",
      " 0.01064688 0.01088296 0.00750157 0.0152735  0.00388585 0.00928931\n",
      " 0.00517287 0.00975452 0.00925336 0.01035011 0.00484153 0.00453146\n",
      " 0.01064688 0.00692385 0.00426635 0.009556   0.00448066 0.01161622\n",
      " 0.00576908 0.01044126 0.01088296 0.01172542 0.0144911  0.0066153\n",
      " 0.00942647 0.00526932 0.01071593 0.01074201 0.00933301 0.00940357\n",
      " 0.00757356 0.0107696  0.01535322 0.00513173 0.01363041 0.01035011\n",
      " 0.01024472 0.01069138 0.01588227 0.00676704 0.01644051 0.00688257\n",
      " 0.0165592  0.01576721 0.00995446 0.0165592  0.00431598 0.00771595\n",
      " 0.0145104  0.00459944 0.00995446 0.01499063 0.01584593 0.00859091\n",
      " 0.0107696  0.00998083 0.00743801 0.01576721 0.01074201 0.00517287\n",
      " 0.01507314 0.01545217 0.00653795 0.00626501 0.00758295 0.01653922\n",
      " 0.00870475 0.00859201 0.01066836 0.00665746 0.01501057 0.01064688\n",
      " 0.01646936 0.01405367 0.00653795 0.01453083 0.0148537  0.00992973\n",
      " 0.0062665  0.00848765 0.01444011 0.00990665 0.01057657 0.0102687\n",
      " 0.00853546 0.01069138 0.00456872 0.00988523 0.01066836 0.0094274\n",
      " 0.00435904 0.00722795 0.00505851 0.00204537 0.00169623 0.00267146\n",
      " 0.00622019 0.00743582 0.00992973 0.00896762 0.00476386 0.01074201\n",
      " 0.0145104  0.01071593 0.01010241 0.00505851 0.0141617  0.00992973\n",
      " 0.00946274 0.00398301 0.00882819 0.00865384 0.00758356 0.01573409\n",
      " 0.01523993 0.01502453 0.00998083 0.00992973 0.01449126 0.0066153\n",
      " 0.0042845  0.00640775 0.00954381 0.00670188 0.00413343 0.00477209\n",
      " 0.0043889  0.01545217 0.01537295 0.00865384 0.01445595 0.00589618\n",
      " 0.01079869 0.01006963 0.01079869 0.00640775 0.01179707 0.01537295\n",
      " 0.01181789 0.00938447 0.00657545 0.01071593 0.00667241 0.00932192\n",
      " 0.00252796 0.00653795 0.0066153  0.00988523 0.00343271 0.01064688\n",
      " 0.0144911  0.00241461 0.00423074 0.0145104  0.00653795 0.01478504\n",
      " 0.00772886 0.01012365 0.01061386 0.01057657 0.00732554 0.0103214\n",
      " 0.00526932 0.00657545 0.01005633 0.01445595 0.0058632  0.00936186\n",
      " 0.01179707 0.00327223 0.00679735 0.01453083 0.00657545 0.00450793\n",
      " 0.01124144 0.00600465 0.00965398 0.00772534 0.01181789 0.01064688\n",
      " 0.0165592  0.00779467 0.01545217 0.01543075 0.00704211 0.00778194\n",
      " 0.01420713 0.01013791 0.00443311 0.01064688 0.00640775 0.00688257\n",
      " 0.00753652 0.01586358 0.00761308 0.01543075 0.00644864 0.00938447\n",
      " 0.01539114 0.00775432 0.01071593 0.00509359 0.01412093 0.00998083\n",
      " 0.01497438 0.00443311 0.01541041 0.00643995 0.00764531 0.00653795\n",
      " 0.00636927 0.01054414 0.00440163 0.00434151 0.00640775 0.00711874\n",
      " 0.00453072 0.0140686  0.0153112  0.01545217 0.00676704 0.0075252\n",
      " 0.00653795 0.00516532 0.00636927 0.00431093 0.01487366 0.00938447\n",
      " 0.00653795 0.00157709 0.00399951 0.00241461 0.0156662  0.00650284\n",
      " 0.01151008 0.00674853 0.00763677 0.00622019 0.00692555 0.00360509\n",
      " 0.00169284 0.01485549 0.00906907 0.00665746 0.00665746 0.00794843\n",
      " 0.00509359 0.00873295 0.00761308 0.00657545 0.01481285 0.00395524\n",
      " 0.01064688 0.00423074 0.01537295 0.0136776  0.00720398 0.01363041\n",
      " 0.00768684 0.00368532 0.0078107  0.00390644 0.00260162 0.0136776\n",
      " 0.00649188 0.01177765 0.01545217 0.01363041 0.01079869 0.01448977\n",
      " 0.0068418  0.01525628 0.00761308 0.00206173 0.00453146 0.01539114\n",
      " 0.01545217 0.01013791 0.01533983 0.00402106 0.01533983 0.01541041\n",
      " 0.00940883 0.00640775 0.01122034 0.01422271 0.0145524  0.00992973\n",
      " 0.01151008 0.01405367 0.00595502 0.01179707 0.00778194 0.00882819\n",
      " 0.00771595 0.00761592 0.01062695 0.01024472 0.00643995 0.00936186\n",
      " 0.00657545 0.01529832 0.0068469  0.01517604 0.0050902  0.01480052\n",
      " 0.00679735 0.01018796 0.01066836 0.01069138 0.0144119  0.00643995\n",
      " 0.0144473  0.00558787 0.01181789 0.00405055 0.0092027  0.00301172\n",
      " 0.00946274 0.0037116  0.0136534  0.00631965 0.0102687  0.00423074\n",
      " 0.00526932 0.00458994 0.00440127 0.00640775 0.00647016 0.00354418\n",
      " 0.00764531 0.00436444 0.01038038 0.01457511 0.00339432 0.00862144\n",
      " 0.01083299 0.00332375 0.00371178 0.00346111 0.0050902  0.00640775\n",
      " 0.00233246 0.01074201 0.00346111 0.01175964 0.00339432 0.00781347\n",
      " 0.00545239 0.00874626 0.00946274 0.00764659 0.00995446 0.01558154\n",
      " 0.00624937 0.00569264 0.00571747 0.00865396 0.00500168 0.00683477\n",
      " 0.00517287 0.01418383 0.00440163 0.00395046 0.00364494 0.00381959\n",
      " 0.0038552  0.01456447 0.00449388 0.00640775 0.00397227 0.00434814\n",
      " 0.00856224 0.00758295 0.0042845  0.00641552 0.00434814 0.01188137\n",
      " 0.01009765 0.01009433 0.00362226 0.01500434 0.00650284 0.00392719\n",
      " 0.00643995 0.00650284 0.00513173 0.00617779 0.01592279 0.01185923\n",
      " 0.01171413 0.00461121 0.01545217 0.00540487 0.01541041 0.01447396\n",
      " 0.01188137 0.01444011 0.01060858 0.00512763 0.0073284  0.00940576\n",
      " 0.00657545 0.00933301 0.01021539 0.00813387 0.01443348 0.01139533\n",
      " 0.0152918  0.00938437 0.01543075 0.00761308 0.0152735  0.01079869\n",
      " 0.01145988 0.0153112  0.00653795 0.00260534 0.00363377 0.0136534\n",
      " 0.00565423 0.01450672 0.01062695 0.00653795 0.00641975 0.00386365\n",
      " 0.00859091 0.0023227  0.01048851 0.01016497 0.00419007 0.01066836\n",
      " 0.01021539 0.0042215  0.00315896 0.00353143 0.01537295 0.00364494\n",
      " 0.01013791 0.01051144 0.01069138 0.0102687  0.01012365 0.01460864\n",
      " 0.01016213 0.00446475 0.00513239 0.01570295 0.00298728 0.00395046\n",
      " 0.00924848 0.00438696 0.0066153  0.0152735  0.00358158 0.00692555\n",
      " 0.00456872 0.00984742 0.01543075 0.00438591 0.01003843 0.01460864\n",
      " 0.01539114 0.00764531 0.01066836 0.0144911  0.00995446 0.01545217\n",
      " 0.01535585 0.00300597 0.00442345 0.01501057 0.01442557 0.0018169\n",
      " 0.00259077 0.00350361 0.00657545 0.00112531 0.00314896 0.00767961\n",
      " 0.00556636 0.002684   0.00463588 0.00674853 0.00352191 0.00517287\n",
      " 0.00423074 0.00938375 0.0102687  0.00981949 0.00986549 0.00488332\n",
      " 0.01062695 0.01066836 0.00358158 0.00443311 0.01524015 0.01041605\n",
      " 0.01069138 0.01145988 0.01058907 0.00413343 0.01016213 0.0136534\n",
      " 0.00657545 0.01083299 0.00764531 0.00858732 0.0101153  0.01066836\n",
      " 0.00995446 0.00412924 0.01410231 0.0102016  0.009347   0.0145524\n",
      " 0.01442557 0.00755495 0.01177765 0.01524015 0.00398301 0.00225062\n",
      " 0.00653795 0.0028974  0.00432353 0.00274965 0.00405055 0.01056582\n",
      " 0.00932192 0.0144473  0.01066722 0.00446475 0.00643995 0.00364494\n",
      " 0.00491964 0.01074201 0.01414073 0.01543075 0.01418383 0.01405367\n",
      " 0.00558278 0.00835602 0.00414108 0.0042845  0.01418383 0.00657545\n",
      " 0.01155251 0.01568405 0.00954055 0.01652025 0.01499192 0.01083299\n",
      " 0.00855666 0.01181913 0.01561904 0.01034991 0.01363041 0.01442557\n",
      " 0.01545217 0.0149087  0.01487366 0.00998083 0.00755332 0.00590785\n",
      " 0.00440127 0.01439954 0.01531106 0.0103214  0.01078907 0.00418034\n",
      " 0.00647016 0.01085722 0.01499192 0.01506285 0.01541041 0.01537295\n",
      " 0.01071593 0.0141617  0.01061386 0.01541041 0.00768684 0.0145104\n",
      " 0.01041674 0.01586358 0.00746872 0.01069138 0.00381959 0.0066153\n",
      " 0.01574393 0.01041218 0.01590201 0.01524015 0.01582933 0.00981949\n",
      " 0.00943493 0.01410231 0.0152112  0.00757356 0.01572292 0.00940883\n",
      " 0.01072827 0.00341434 0.01570295 0.00925336 0.01018796 0.01505118\n",
      " 0.01457511 0.01069138 0.01559195 0.01543075 0.01426795 0.01570295\n",
      " 0.00855666 0.00653795 0.00961967 0.01572292 0.01541041 0.01522512\n",
      " 0.00509359 0.00933301 0.01071593 0.00434151 0.01650227 0.0145104\n",
      " 0.00933301 0.0153249  0.00758295 0.01064688 0.01066836 0.00590785\n",
      " 0.01529832 0.01529832 0.0165592  0.01453083 0.01363041 0.01644051\n",
      " 0.01640488 0.01064688 0.00405055 0.01499192 0.01586358 0.01056582\n",
      " 0.01041218 0.01066836 0.00700711 0.0042845  0.01024472 0.01069138\n",
      " 0.00448066 0.00375467 0.0136776  0.0092027  0.00448066 0.01184011\n",
      " 0.0102444  0.01533983 0.00794843 0.01545217 0.00676964 0.01525628\n",
      " 0.01457511 0.0136776  0.0066153  0.01069138 0.01453083 0.00938375\n",
      " 0.00847602 0.01064019 0.01071593 0.01079869 0.00446732 0.01048201\n",
      " 0.01018796 0.01535585 0.01570295 0.01363041 0.01157996 0.00657545\n",
      " 0.00513173 0.01582933 0.00339432 0.00622019 0.00886401 0.009556\n",
      " 0.00334207 0.01064688 0.01008205 0.0101153  0.01013791 0.00358158\n",
      " 0.01018796 0.00941171 0.01533167 0.01539114 0.01074201 0.00975452\n",
      " 0.01000995 0.01022236 0.00997673 0.01179707 0.01045937 0.01000995\n",
      " 0.00460665 0.01410231 0.0102687  0.01024472 0.00407343 0.01539114\n",
      " 0.00440163 0.01535585 0.00467078 0.00758295 0.00509359 0.0102016\n",
      " 0.00758295 0.00412078 0.01166958 0.00418034 0.01570295 0.00638771\n",
      " 0.01021986 0.01138908 0.00650284 0.01646936 0.0165592  0.01537295\n",
      " 0.01022236 0.00564979 0.01535585 0.01241016 0.00423074 0.00853546\n",
      " 0.01024472 0.00527595 0.01478994 0.00452959 0.00952668 0.01491692\n",
      " 0.00407343 0.01012365 0.01038038 0.01078907 0.01038038 0.00271998\n",
      " 0.00567524 0.00940357 0.00570356 0.00518531 0.00981949 0.01009433\n",
      " 0.01024472 0.00995446 0.01483485 0.00986549 0.00397227 0.0152112\n",
      " 0.00938375 0.01405367 0.01006981 0.01035011 0.01016213 0.00740604\n",
      " 0.00988523 0.0102687  0.01537295 0.01078907 0.00561964 0.0102687\n",
      " 0.01445595 0.0144473  0.01444011 0.01525628 0.01035011 0.00568326\n",
      " 0.0152735  0.0145524  0.01646936 0.00412924 0.00413343 0.01539114\n",
      " 0.0042845  0.0018169  0.0144473  0.01179707 0.00600465 0.01186372\n",
      " 0.00650284 0.00397227 0.00650284 0.00346111 0.01050547 0.00571747\n",
      " 0.00563977 0.01148427 0.00458994 0.00246341 0.01035011 0.01133159\n",
      " 0.0107696  0.00587168 0.01644051 0.00748391 0.01131964 0.00467848\n",
      " 0.00423074 0.00507208 0.01145988 0.00749925 0.01248846 0.00775432\n",
      " 0.0034661  0.01169043 0.01239307 0.00518661 0.0066153  0.01531106\n",
      " 0.00423074 0.00423074 0.00364494 0.00332375 0.01236293 0.00440163\n",
      " 0.00958346 0.00369623 0.01533167 0.01541041 0.00650284]\n",
      "[0.00820993 0.01041062 0.00961265 0.01040618 0.00366665 0.00603006\n",
      " 0.00823056 0.00599481 0.01035178 0.0034468  0.00365147 0.01321694\n",
      " 0.00908282 0.00728663 0.00606371 0.00958997 0.01472709 0.01328316\n",
      " 0.00606371 0.00597117 0.00967072 0.00353827 0.01532816 0.00828236\n",
      " 0.01326272 0.00733701 0.00859852 0.00712539 0.01414937 0.01375277\n",
      " 0.00606371 0.01039884 0.01450943 0.00812836 0.01376078 0.00673418\n",
      " 0.01330672 0.0071091  0.00597117 0.00570934 0.00416546 0.01035751\n",
      " 0.00818553 0.01324606 0.00601739 0.00600752 0.00824954 0.00833481\n",
      " 0.00965668 0.00600046 0.00349972 0.0132723  0.0047137  0.00712539\n",
      " 0.00716337 0.00603006 0.00173809 0.01035286 0.00091153 0.01033073\n",
      " 0.         0.00188181 0.00718163 0.         0.01386233 0.0095888\n",
      " 0.00415118 0.01377866 0.00718163 0.00293854 0.00179568 0.00909779\n",
      " 0.00600046 0.007171   0.00969174 0.00188181 0.00600752 0.01326272\n",
      " 0.00286711 0.00343694 0.01037387 0.01151158 0.00962411 0.00013022\n",
      " 0.00911637 0.00919508 0.00604551 0.01035178 0.0028936  0.00606371\n",
      " 0.00065109 0.00371416 0.01037387 0.00414096 0.00323901 0.00719461\n",
      " 0.01302048 0.00914983 0.00423209 0.00720991 0.00616356 0.00715034\n",
      " 0.00912013 0.00603006 0.01420561 0.00722753 0.00604551 0.01190826\n",
      " 0.01450725 0.01118452 0.01329528 0.01622604 0.016293   0.01557602\n",
      " 0.01151673 0.01116504 0.00719461 0.01199509 0.01417093 0.00600752\n",
      " 0.00415118 0.00601739 0.00715206 0.01329528 0.00365507 0.00719461\n",
      " 0.00820993 0.01388165 0.00905887 0.00908287 0.0099377  0.00226699\n",
      " 0.00369082 0.00288025 0.007171   0.00719461 0.00486443 0.01035751\n",
      " 0.01380018 0.0104277  0.00912184 0.01034769 0.0138278  0.01500596\n",
      " 0.01378048 0.00343694 0.00347619 0.00908287 0.00420597 0.0139498\n",
      " 0.00599622 0.00715324 0.00599622 0.0104277  0.00561041 0.00347619\n",
      " 0.00559377 0.00824394 0.01036488 0.00601739 0.01038965 0.00829623\n",
      " 0.01559561 0.01037387 0.01035751 0.00722753 0.01479723 0.00606371\n",
      " 0.00416546 0.01564576 0.01380816 0.00415118 0.01037387 0.00334207\n",
      " 0.00962967 0.00737958 0.00612498 0.00616356 0.01121353 0.00713134\n",
      " 0.01324606 0.01036488 0.00883384 0.00420597 0.01105425 0.00825935\n",
      " 0.00561041 0.01478994 0.01034441 0.00414096 0.01036488 0.01425132\n",
      " 0.00706728 0.01103813 0.00811897 0.00991036 0.00559377 0.00606371\n",
      " 0.         0.00958173 0.00343694 0.00343941 0.01034322 0.00991576\n",
      " 0.00364578 0.00725398 0.01377002 0.00606371 0.0104277  0.01033073\n",
      " 0.00966282 0.00176232 0.00961265 0.00343941 0.01042038 0.00824394\n",
      " 0.00345907 0.00958438 0.00601739 0.01328316 0.0036828  0.007171\n",
      " 0.0029401  0.01377002 0.0034468  0.01041058 0.00960294 0.01037387\n",
      " 0.01043664 0.00617049 0.01378789 0.01379342 0.0104277  0.0103301\n",
      " 0.0137805  0.003758   0.00350939 0.00343694 0.01035286 0.00996155\n",
      " 0.01037387 0.01330737 0.01043664 0.01380507 0.00322589 0.00824394\n",
      " 0.01037387 0.01630184 0.01509459 0.01564576 0.00235339 0.01038449\n",
      " 0.00676017 0.01034523 0.01000768 0.01151673 0.01032662 0.01475263\n",
      " 0.0163785  0.003167   0.00974834 0.01035178 0.01035178 0.00956164\n",
      " 0.01328316 0.00910613 0.00961265 0.01036488 0.0031669  0.01389813\n",
      " 0.00606371 0.01380816 0.00347619 0.0047065  0.01032353 0.0047137\n",
      " 0.00991463 0.01471714 0.00958997 0.01470504 0.01572185 0.0047065\n",
      " 0.01041469 0.00563002 0.00343694 0.0047137  0.00599622 0.00418263\n",
      " 0.01033647 0.00355977 0.00961265 0.01627269 0.01375277 0.00345907\n",
      " 0.00343694 0.00725398 0.00352463 0.01389593 0.00352463 0.0034468\n",
      " 0.00823056 0.0104277  0.0070271  0.00564918 0.00413481 0.00719461\n",
      " 0.00676017 0.00371416 0.01104197 0.00561041 0.00991576 0.00905887\n",
      " 0.0095888  0.00992831 0.00608465 0.00716337 0.01041058 0.00825935\n",
      " 0.01036488 0.00363126 0.01271552 0.00378151 0.01333628 0.00330893\n",
      " 0.01034441 0.00723056 0.00604551 0.00603006 0.00429572 0.01041058\n",
      " 0.00418714 0.01333814 0.00559377 0.0138523  0.00973441 0.01488862\n",
      " 0.00820993 0.01456716 0.0047083  0.01275618 0.00715034 0.01380816\n",
      " 0.01324606 0.01422989 0.01431626 0.0104277  0.01039673 0.01485557\n",
      " 0.00960294 0.01506086 0.00712182 0.00413276 0.01477158 0.0090894\n",
      " 0.00599385 0.0147524  0.01468385 0.01476412 0.01333628 0.0104277\n",
      " 0.01565497 0.00600752 0.01476412 0.00565257 0.01477158 0.00990635\n",
      " 0.01329099 0.00984502 0.00820993 0.01305296 0.00718163 0.00263872\n",
      " 0.01155401 0.01262181 0.0132554  0.00914237 0.01345827 0.01227481\n",
      " 0.01326272 0.0036481  0.01378789 0.01510414 0.0146902  0.01459821\n",
      " 0.01467461 0.00411726 0.01422946 0.0104277  0.0139063  0.01379217\n",
      " 0.00910804 0.00962411 0.01380018 0.01269756 0.01379217 0.00556254\n",
      " 0.00738992 0.00728663 0.01485158 0.00290861 0.01038449 0.01391788\n",
      " 0.01041058 0.01038449 0.0132723  0.01152336 0.00171847 0.00557624\n",
      " 0.00573743 0.01419546 0.00343694 0.01345877 0.0034468  0.0042089\n",
      " 0.00556254 0.00423209 0.00610829 0.01431191 0.0100573  0.00820312\n",
      " 0.01036488 0.00824954 0.00722235 0.01250915 0.00431041 0.00681637\n",
      " 0.00352145 0.00858273 0.00343941 0.00961265 0.00353827 0.00599622\n",
      " 0.0067752  0.00350939 0.01037387 0.0155075  0.01471607 0.0047083\n",
      " 0.01331523 0.00416028 0.00608465 0.01037387 0.01150445 0.01512658\n",
      " 0.00909779 0.01574286 0.00624017 0.00723872 0.01458368 0.00604551\n",
      " 0.00722235 0.01385105 0.01487659 0.0147578  0.00347619 0.0146902\n",
      " 0.00725398 0.00653609 0.00603006 0.00715034 0.00737958 0.00410901\n",
      " 0.00724111 0.01378358 0.01334554 0.00230976 0.01554331 0.01510414\n",
      " 0.00842847 0.01429129 0.01035751 0.00353827 0.0146977  0.01032662\n",
      " 0.01420561 0.00726964 0.00343941 0.01430832 0.0071568  0.00410901\n",
      " 0.00345907 0.00960294 0.00604551 0.00416546 0.00718163 0.00343694\n",
      " 0.00349807 0.01554987 0.01428203 0.0028936  0.00419321 0.01628519\n",
      " 0.01563058 0.01479092 0.01036488 0.01634754 0.01490344 0.00959499\n",
      " 0.01213249 0.01562461 0.01422095 0.01034523 0.01470635 0.01326272\n",
      " 0.01380816 0.00822483 0.00715034 0.00728483 0.00724744 0.01349036\n",
      " 0.00608465 0.00604551 0.0146977  0.01377002 0.00358587 0.00711982\n",
      " 0.00603006 0.0067752  0.00613742 0.0138278  0.00724111 0.0047083\n",
      " 0.01036488 0.00599385 0.00960294 0.00912165 0.00726916 0.00604551\n",
      " 0.00718163 0.01387884 0.00370346 0.00719643 0.00828911 0.00413481\n",
      " 0.00419321 0.00963731 0.00563002 0.00358587 0.01388165 0.01621141\n",
      " 0.01037387 0.01557812 0.01433993 0.01556786 0.0138523  0.0061526\n",
      " 0.00829623 0.00418714 0.00627863 0.01378358 0.01041058 0.0146902\n",
      " 0.01347841 0.00600752 0.00366665 0.00343941 0.0036481  0.00371416\n",
      " 0.01398862 0.00947291 0.01513576 0.01380018 0.0036481  0.01036488\n",
      " 0.00674567 0.00232804 0.00819902 0.00026044 0.00291404 0.00599385\n",
      " 0.00913001 0.00561261 0.00246942 0.00716612 0.0047137  0.00419321\n",
      " 0.00343694 0.00296789 0.00322589 0.007171   0.00994878 0.01104734\n",
      " 0.01431626 0.00433306 0.00359135 0.00713134 0.0060277  0.01381737\n",
      " 0.01039673 0.0059811  0.00291404 0.00284471 0.0034468  0.00347619\n",
      " 0.00601739 0.00365507 0.00612498 0.0034468  0.00991463 0.00415118\n",
      " 0.00842259 0.00176232 0.00968036 0.00603006 0.01459821 0.01035751\n",
      " 0.00229503 0.00712063 0.0017234  0.00358587 0.00183768 0.00728483\n",
      " 0.00821922 0.00370346 0.00365147 0.00965668 0.00229872 0.00823056\n",
      " 0.00610279 0.01472709 0.00230976 0.00859852 0.00723056 0.00287006\n",
      " 0.00413276 0.00603006 0.00324509 0.00343941 0.00564318 0.00230976\n",
      " 0.00913001 0.01037387 0.00812001 0.00229872 0.0034468  0.00361648\n",
      " 0.01328316 0.00824954 0.00601739 0.01379342 0.00039065 0.00415118\n",
      " 0.00824954 0.00355576 0.00962411 0.00606371 0.00604551 0.01104734\n",
      " 0.00363126 0.00363126 0.         0.00414096 0.0047137  0.00091153\n",
      " 0.00130218 0.00606371 0.0138523  0.00291404 0.00176232 0.0061526\n",
      " 0.00712063 0.00604551 0.01035223 0.01380018 0.00716337 0.00603006\n",
      " 0.01376078 0.01460459 0.0047065  0.00973441 0.01376078 0.00558011\n",
      " 0.00721648 0.00352463 0.00956164 0.00343694 0.01278428 0.00355977\n",
      " 0.00413276 0.0047065  0.01035751 0.00603006 0.00414096 0.00822483\n",
      " 0.00916615 0.00611528 0.00601739 0.00599622 0.01427194 0.00634445\n",
      " 0.00723056 0.00349807 0.00230976 0.0047137  0.00810177 0.01036488\n",
      " 0.0132723  0.00183768 0.01477158 0.01151673 0.00908376 0.00812836\n",
      " 0.01478504 0.00606371 0.00716428 0.00726916 0.00725398 0.0146977\n",
      " 0.00723056 0.00821555 0.00350214 0.00345907 0.00600752 0.00733701\n",
      " 0.00745389 0.00717874 0.00866777 0.00561041 0.00629967 0.00745389\n",
      " 0.01517194 0.00370346 0.00715034 0.00716337 0.01388678 0.00345907\n",
      " 0.01378789 0.00349807 0.01377804 0.00962411 0.01328316 0.00719643\n",
      " 0.00962411 0.0145141  0.00589693 0.01381737 0.00230976 0.01271024\n",
      " 0.00712274 0.00686228 0.01038449 0.00065109 0.         0.00347619\n",
      " 0.00717874 0.01328438 0.00349807 0.00651936 0.01380816 0.00912013\n",
      " 0.00716337 0.01419951 0.00327223 0.01421694 0.00813566 0.00321536\n",
      " 0.01388678 0.00737958 0.00712182 0.0060277  0.00712182 0.01548342\n",
      " 0.01326969 0.00833481 0.01325627 0.01433339 0.00728483 0.00728663\n",
      " 0.00716337 0.00718163 0.00325728 0.00724744 0.0139063  0.00365147\n",
      " 0.00822483 0.00371416 0.0085343  0.00712539 0.00724111 0.01242098\n",
      " 0.00722753 0.00715034 0.00347619 0.0060277  0.01332605 0.00715034\n",
      " 0.00420597 0.00418714 0.00423209 0.00355977 0.00712539 0.01326626\n",
      " 0.00353827 0.00413481 0.00065109 0.01387884 0.0138278  0.00345907\n",
      " 0.01380018 0.01628519 0.00418714 0.00561041 0.01103813 0.00556946\n",
      " 0.01038449 0.0139063  0.01038449 0.01476412 0.0062143  0.0132554\n",
      " 0.01332773 0.00676643 0.01422989 0.01560702 0.00712539 0.00701913\n",
      " 0.00600046 0.01321694 0.00091153 0.00968733 0.00689556 0.01423165\n",
      " 0.01380816 0.01430058 0.0067752  0.00997601 0.00662309 0.00958438\n",
      " 0.01471615 0.00589614 0.00653884 0.01329015 0.01035751 0.00359135\n",
      " 0.01380816 0.01380816 0.0146902  0.0147524  0.00658535 0.01378789\n",
      " 0.00884529 0.01470858 0.00350214 0.0034468  0.01038449]\n"
     ]
    }
   ],
   "source": [
    "# Step 7: Calculate the Euclidean distances from the ideal and negative-ideal solutions\n",
    "distance_to_ideal = np.sqrt(np.sum((weighted_normalized_matrix - ideal_solution) ** 2, axis=1))\n",
    "distance_to_negative_ideal = np.sqrt(np.sum((weighted_normalized_matrix - negative_ideal_solution) ** 2, axis=1))\n",
    "\n",
    "print(distance_to_ideal)\n",
    "print(distance_to_negative_ideal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.46455511 0.61426638 0.55804022 0.60179261 0.20590612 0.36061851\n",
      " 0.46660112 0.35632315 0.60859763 0.18278399 0.19358193 0.69239887\n",
      " 0.5050487  0.41923064 0.3628664  0.55112654 0.81179318 0.7228242\n",
      " 0.3628664  0.35428524 0.56315849 0.18808794 0.79775941 0.47134738\n",
      " 0.71940846 0.42927761 0.48165925 0.40773605 0.7450604  0.75216542\n",
      " 0.3628664  0.60030162 0.77277389 0.45963553 0.75436903 0.3669774\n",
      " 0.69757072 0.40506864 0.35428524 0.32746877 0.2232704  0.61024153\n",
      " 0.46476988 0.71540842 0.3596053  0.35866802 0.46918883 0.46987423\n",
      " 0.56044971 0.35780794 0.18563239 0.72116271 0.25695984 0.40773605\n",
      " 0.41149649 0.36061851 0.0986412  0.60472678 0.05253143 0.60015966\n",
      " 0.         0.10662383 0.41909384 0.         0.76257553 0.55411376\n",
      " 0.22244552 0.74973255 0.41909384 0.16389695 0.10178642 0.51432797\n",
      " 0.35780794 0.41808943 0.56578414 0.10662383 0.35866802 0.71940846\n",
      " 0.15981419 0.18195364 0.61340962 0.64756969 0.55931164 0.00781179\n",
      " 0.51154843 0.51695227 0.36170613 0.60859763 0.16161582 0.3628664\n",
      " 0.03803    0.20903834 0.61340962 0.22177627 0.17902284 0.42013922\n",
      " 0.6750916  0.51877205 0.22665203 0.42122418 0.36819074 0.41048993\n",
      " 0.51655766 0.36061851 0.75665047 0.42234724 0.36170613 0.55813894\n",
      " 0.76895079 0.60744261 0.72438864 0.88805638 0.90570831 0.85359866\n",
      " 0.64930844 0.60024328 0.42013922 0.57221089 0.74840703 0.35866802\n",
      " 0.22244552 0.3596053  0.41450456 0.72438864 0.20514767 0.42013922\n",
      " 0.46455511 0.77704546 0.50644811 0.51209447 0.56717925 0.12593623\n",
      " 0.19496428 0.16086502 0.41808943 0.42013922 0.25131788 0.61024153\n",
      " 0.76308655 0.61938944 0.48869671 0.60691782 0.7698694  0.75871788\n",
      " 0.75844539 0.18195364 0.18442154 0.51209447 0.22537701 0.70290298\n",
      " 0.35702607 0.41533386 0.35702607 0.61938944 0.32229896 0.18442154\n",
      " 0.32126554 0.4676508  0.61184651 0.3596053  0.60893292 0.47089084\n",
      " 0.86051537 0.61340962 0.61024153 0.42234724 0.81169917 0.3628664\n",
      " 0.2232704  0.86630322 0.76546585 0.22244552 0.61340962 0.18436863\n",
      " 0.55475157 0.42161257 0.36591409 0.36819074 0.60485944 0.4086086\n",
      " 0.71540842 0.61184651 0.46764216 0.22537701 0.65342311 0.46871655\n",
      " 0.32229896 0.81883504 0.60346261 0.22177627 0.61184651 0.75969574\n",
      " 0.38600605 0.64767207 0.45681603 0.5619486  0.32126554 0.3628664\n",
      " 0.         0.55142211 0.18195364 0.18226702 0.59493962 0.56028542\n",
      " 0.20421204 0.41708974 0.75646458 0.3628664  0.61938944 0.60015966\n",
      " 0.56181347 0.09998445 0.55804022 0.18226702 0.61772301 0.4676508\n",
      " 0.18350308 0.55277403 0.3596053  0.7228242  0.20685547 0.41808943\n",
      " 0.16411883 0.75646458 0.18278399 0.61781917 0.55674881 0.61340962\n",
      " 0.62101035 0.36916698 0.75801261 0.76059947 0.61938944 0.59202196\n",
      " 0.75257133 0.21080869 0.18646563 0.18195364 0.60472678 0.56966271\n",
      " 0.61340962 0.72038069 0.62101035 0.76203727 0.17823052 0.4676508\n",
      " 0.61340962 0.91179066 0.79053679 0.86630322 0.13060192 0.61492796\n",
      " 0.37000963 0.60520513 0.56718578 0.64930844 0.59856934 0.80361998\n",
      " 0.90632483 0.17572482 0.51804903 0.60859763 0.60859763 0.54606527\n",
      " 0.7228242  0.5104595  0.55804022 0.61184651 0.17613688 0.77845989\n",
      " 0.3628664  0.76546585 0.18442154 0.25600921 0.58898991 0.25695984\n",
      " 0.56328444 0.79973766 0.55112654 0.79010571 0.85801714 0.25600921\n",
      " 0.61601424 0.32342201 0.18195364 0.25695984 0.35702607 0.22400086\n",
      " 0.60171781 0.18918779 0.55804022 0.88754888 0.75216542 0.18350308\n",
      " 0.18195364 0.41708974 0.18683972 0.77557287 0.18683972 0.18278399\n",
      " 0.46660112 0.61938944 0.38510063 0.28427999 0.22126426 0.42013922\n",
      " 0.37000963 0.20903834 0.64964259 0.32229896 0.56028542 0.50644811\n",
      " 0.55411376 0.5659017  0.36409731 0.41149649 0.61781917 0.46871655\n",
      " 0.61184651 0.19183007 0.64999743 0.19947229 0.72375643 0.18271832\n",
      " 0.60346261 0.41510763 0.36170613 0.36061851 0.22962415 0.61781917\n",
      " 0.22469893 0.70475187 0.32126554 0.77374835 0.51403883 0.83175087\n",
      " 0.46455511 0.79694458 0.25641955 0.6687091  0.41048993 0.76546585\n",
      " 0.71540842 0.75611167 0.76485831 0.61938944 0.61639872 0.80737887\n",
      " 0.55674881 0.77532189 0.40691017 0.22091036 0.8131487  0.51321099\n",
      " 0.35620757 0.81612533 0.79822483 0.81009251 0.72375643 0.61938944\n",
      " 0.8703285  0.35866802 0.81009251 0.32463252 0.8131487  0.55905492\n",
      " 0.7091031  0.52955052 0.46455511 0.63059137 0.41909384 0.14482323\n",
      " 0.6489786  0.68917203 0.69865021 0.51372225 0.72905221 0.64233809\n",
      " 0.71940846 0.20458254 0.75801261 0.79267702 0.80120475 0.79261417\n",
      " 0.79194611 0.22038954 0.75998505 0.61938944 0.7778196  0.76030502\n",
      " 0.51544401 0.55931164 0.76308655 0.66433885 0.76030502 0.31888151\n",
      " 0.42258105 0.41923064 0.8039247  0.16237454 0.61492796 0.7799286\n",
      " 0.61781917 0.61492796 0.72116271 0.65099493 0.09741204 0.3198217\n",
      " 0.32876306 0.75480985 0.18195364 0.71347662 0.18278399 0.22528148\n",
      " 0.31888151 0.22665203 0.36539665 0.73622671 0.5784813  0.46585112\n",
      " 0.61184651 0.46918883 0.4141793  0.60597486 0.22996353 0.37428518\n",
      " 0.1871793  0.47769153 0.18226702 0.55804022 0.18808794 0.35702607\n",
      " 0.37154759 0.18646563 0.61340962 0.85616035 0.80197285 0.25641955\n",
      " 0.70192976 0.22286795 0.36409731 0.61340962 0.64183899 0.79654514\n",
      " 0.51432797 0.8714296  0.37302226 0.41593035 0.77681222 0.36170613\n",
      " 0.4141793  0.7664136  0.8248483  0.80691199 0.18442154 0.80120475\n",
      " 0.41708974 0.38340385 0.36061851 0.41048993 0.42161257 0.21952599\n",
      " 0.41607818 0.75533394 0.72224227 0.12822928 0.8387918  0.79267702\n",
      " 0.47680571 0.76513016 0.61024153 0.18808794 0.80406323 0.59856934\n",
      " 0.75665047 0.4247012  0.18226702 0.76538711 0.41620837 0.21952599\n",
      " 0.18350308 0.55674881 0.36170613 0.2232704  0.41909384 0.18195364\n",
      " 0.18553543 0.83800431 0.76352112 0.16161582 0.22521394 0.89963027\n",
      " 0.85781658 0.80848881 0.61184651 0.93559672 0.8255654  0.55543934\n",
      " 0.68549595 0.8534023  0.7541536  0.60520513 0.80678864 0.71940846\n",
      " 0.76546585 0.46709233 0.41048993 0.42590567 0.42350681 0.73422197\n",
      " 0.36409731 0.36170613 0.80406323 0.75646458 0.19047407 0.40601468\n",
      " 0.36061851 0.37154759 0.36692824 0.7698694  0.41607818 0.25641955\n",
      " 0.61184651 0.35620757 0.55674881 0.5150863  0.41814103 0.36170613\n",
      " 0.41909384 0.77070046 0.20799219 0.41363489 0.47000787 0.22126426\n",
      " 0.22521394 0.56056117 0.32342201 0.19047407 0.77704546 0.87809473\n",
      " 0.61340962 0.84317626 0.76834245 0.84988935 0.77374835 0.36801311\n",
      " 0.47089084 0.22469893 0.37051153 0.75533394 0.61781917 0.80120475\n",
      " 0.73259976 0.35866802 0.20590612 0.18226702 0.20458254 0.20903834\n",
      " 0.71474824 0.53132229 0.78517865 0.76308655 0.20458254 0.61184651\n",
      " 0.3686525  0.12924868 0.46218817 0.01552001 0.16274111 0.35620757\n",
      " 0.5162085  0.3219767  0.13651903 0.4091176  0.25695984 0.22521394\n",
      " 0.18195364 0.16602086 0.17823052 0.41808943 0.56843354 0.65156096\n",
      " 0.76485831 0.23131116 0.18999436 0.4086086  0.35843379 0.76772941\n",
      " 0.61639872 0.35520763 0.16274111 0.15885525 0.18278399 0.18442154\n",
      " 0.3596053  0.20514767 0.36591409 0.18278399 0.56328444 0.22244552\n",
      " 0.44707473 0.09998445 0.56448273 0.36061851 0.79261417 0.61024153\n",
      " 0.12722612 0.40613174 0.09777918 0.19047407 0.10401751 0.42590567\n",
      " 0.4655688  0.20799219 0.19358193 0.56044971 0.12755325 0.46660112\n",
      " 0.36259085 0.81179318 0.12822928 0.48165925 0.41510763 0.16014852\n",
      " 0.22091036 0.36061851 0.17227173 0.18226702 0.28341827 0.12822928\n",
      " 0.5162085  0.61340962 0.45773157 0.12755325 0.18278399 0.19194099\n",
      " 0.7228242  0.46918883 0.3596053  0.76059947 0.02312532 0.22244552\n",
      " 0.46918883 0.18832834 0.55931164 0.3628664  0.36170613 0.65156096\n",
      " 0.19183007 0.19183007 0.         0.22177627 0.25695984 0.05253143\n",
      " 0.07354022 0.3628664  0.77374835 0.16274111 0.09998445 0.36801311\n",
      " 0.40613174 0.36170613 0.5963495  0.76308655 0.41149649 0.36061851\n",
      " 0.75436903 0.79548922 0.25600921 0.51403883 0.75436903 0.32032363\n",
      " 0.41329422 0.18683972 0.54606527 0.18195364 0.65379622 0.18918779\n",
      " 0.22091036 0.25600921 0.61024153 0.36061851 0.22177627 0.46709233\n",
      " 0.51955917 0.36497215 0.3596053  0.35702607 0.76160641 0.37705219\n",
      " 0.41510763 0.18553543 0.12822928 0.25695984 0.41163926 0.61184651\n",
      " 0.72116271 0.10401751 0.8131487  0.64930844 0.50612195 0.45963553\n",
      " 0.81563137 0.3628664  0.41540907 0.41814103 0.41708974 0.80406323\n",
      " 0.41510763 0.46607061 0.18594953 0.18350308 0.35866802 0.42927761\n",
      " 0.42681838 0.41254528 0.46489691 0.32229896 0.37589679 0.42681838\n",
      " 0.76708915 0.20799219 0.41048993 0.41149649 0.77319693 0.18350308\n",
      " 0.75801261 0.18553543 0.74682516 0.55931164 0.7228242  0.41363489\n",
      " 0.55931164 0.77886743 0.33569145 0.76772941 0.12822928 0.66552921\n",
      " 0.41070777 0.37598742 0.61492796 0.03803    0.         0.18442154\n",
      " 0.41254528 0.70160878 0.18553543 0.34440174 0.76546585 0.51655766\n",
      " 0.41149649 0.72909737 0.18116496 0.75837732 0.46062191 0.17732807\n",
      " 0.77319693 0.42161257 0.40691017 0.35843379 0.40691017 0.85057871\n",
      " 0.7004348  0.46987423 0.69917669 0.73434151 0.42590567 0.41923064\n",
      " 0.41149649 0.41909384 0.18003847 0.42350681 0.7778196  0.19358193\n",
      " 0.46709233 0.20903834 0.45873216 0.40773605 0.41607818 0.62646736\n",
      " 0.42234724 0.41048993 0.18442154 0.35843379 0.70338167 0.41048993\n",
      " 0.22537701 0.22469893 0.22665203 0.18918779 0.40773605 0.70008431\n",
      " 0.18808794 0.22126426 0.03803    0.77070046 0.7698694  0.18350308\n",
      " 0.76308655 0.89963027 0.22469893 0.32229896 0.64767207 0.31947481\n",
      " 0.61492796 0.7778196  0.61492796 0.81009251 0.3716738  0.69865021\n",
      " 0.70266123 0.37074926 0.75611167 0.8636772  0.40773605 0.38249882\n",
      " 0.35780794 0.69239887 0.05253143 0.5641601  0.37856086 0.75259408\n",
      " 0.76546585 0.73818375 0.37154759 0.57086494 0.3465492  0.55277403\n",
      " 0.80936921 0.335264   0.34538718 0.71928996 0.61024153 0.18999436\n",
      " 0.76546585 0.76546585 0.80120475 0.81612533 0.34754342 0.75801261\n",
      " 0.47997232 0.79917059 0.18594953 0.18278399 0.61492796]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Step 8: Calculate the relative closeness to the ideal solution\n",
    "closeness = distance_to_negative_ideal / (distance_to_ideal + distance_to_negative_ideal)\n",
    "\n",
    "print(closeness)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rank 1: AlunoId 496\n",
      "Rank 2: AlunoId 248\n",
      "Rank 3: AlunoId 259\n",
      "Rank 4: AlunoId 113\n",
      "Rank 5: AlunoId 492\n",
      "Rank 6: AlunoId 800\n",
      "Rank 7: AlunoId 112\n",
      "Rank 8: AlunoId 292\n",
      "Rank 9: AlunoId 540\n",
      "Rank 10: AlunoId 446\n",
      "Rank 11: AlunoId 361\n",
      "Rank 12: AlunoId 250\n",
      "Rank 13: AlunoId 170\n",
      "Rank 14: AlunoId 814\n",
      "Rank 15: AlunoId 163\n",
      "Rank 16: AlunoId 281\n",
      "Rank 17: AlunoId 493\n",
      "Rank 18: AlunoId 436\n",
      "Rank 19: AlunoId 114\n",
      "Rank 20: AlunoId 500\n",
      "Rank 21: AlunoId 762\n",
      "Rank 22: AlunoId 544\n",
      "Rank 23: AlunoId 542\n",
      "Rank 24: AlunoId 467\n",
      "Rank 25: AlunoId 488\n",
      "Rank 26: AlunoId 336\n",
      "Rank 27: AlunoId 497\n",
      "Rank 28: AlunoId 453\n",
      "Rank 29: AlunoId 188\n",
      "Rank 30: AlunoId 838\n",
      "Rank 31: AlunoId 356\n",
      "Rank 32: AlunoId 703\n",
      "Rank 33: AlunoId 365\n",
      "Rank 34: AlunoId 353\n",
      "Rank 35: AlunoId 699\n",
      "Rank 36: AlunoId 17\n",
      "Rank 37: AlunoId 620\n",
      "Rank 38: AlunoId 167\n",
      "Rank 39: AlunoId 358\n",
      "Rank 40: AlunoId 808\n",
      "Rank 41: AlunoId 363\n",
      "Rank 42: AlunoId 829\n",
      "Rank 43: AlunoId 494\n",
      "Rank 44: AlunoId 348\n",
      "Rank 45: AlunoId 454\n",
      "Rank 46: AlunoId 503\n",
      "Rank 47: AlunoId 513\n",
      "Rank 48: AlunoId 473\n",
      "Rank 49: AlunoId 708\n",
      "Rank 50: AlunoId 399\n",
      "Rank 51: AlunoId 258\n",
      "Rank 52: AlunoId 437\n",
      "Rank 53: AlunoId 552\n",
      "Rank 54: AlunoId 837\n",
      "Rank 55: AlunoId 383\n",
      "Rank 56: AlunoId 456\n",
      "Rank 57: AlunoId 278\n",
      "Rank 58: AlunoId 842\n",
      "Rank 59: AlunoId 357\n",
      "Rank 60: AlunoId 23\n",
      "Rank 61: AlunoId 338\n",
      "Rank 62: AlunoId 444\n",
      "Rank 63: AlunoId 668\n",
      "Rank 64: AlunoId 382\n",
      "Rank 65: AlunoId 468\n",
      "Rank 66: AlunoId 605\n",
      "Rank 67: AlunoId 384\n",
      "Rank 68: AlunoId 385\n",
      "Rank 69: AlunoId 249\n",
      "Rank 70: AlunoId 280\n",
      "Rank 71: AlunoId 561\n",
      "Rank 72: AlunoId 402\n",
      "Rank 73: AlunoId 734\n",
      "Rank 74: AlunoId 270\n",
      "Rank 75: AlunoId 806\n",
      "Rank 76: AlunoId 773\n",
      "Rank 77: AlunoId 389\n",
      "Rank 78: AlunoId 128\n",
      "Rank 79: AlunoId 539\n",
      "Rank 80: AlunoId 449\n",
      "Rank 81: AlunoId 298\n",
      "Rank 82: AlunoId 350\n",
      "Rank 83: AlunoId 657\n",
      "Rank 84: AlunoId 334\n",
      "Rank 85: AlunoId 545\n",
      "Rank 86: AlunoId 725\n",
      "Rank 87: AlunoId 757\n",
      "Rank 88: AlunoId 33\n",
      "Rank 89: AlunoId 530\n",
      "Rank 90: AlunoId 796\n",
      "Rank 91: AlunoId 143\n",
      "Rank 92: AlunoId 797\n",
      "Rank 93: AlunoId 520\n",
      "Rank 94: AlunoId 109\n",
      "Rank 95: AlunoId 543\n",
      "Rank 96: AlunoId 736\n",
      "Rank 97: AlunoId 588\n",
      "Rank 98: AlunoId 721\n",
      "Rank 99: AlunoId 452\n",
      "Rank 100: AlunoId 835\n",
      "Rank 101: AlunoId 836\n",
      "Rank 102: AlunoId 823\n",
      "Rank 103: AlunoId 171\n",
      "Rank 104: AlunoId 749\n",
      "Rank 105: AlunoId 342\n",
      "Rank 106: AlunoId 505\n",
      "Rank 107: AlunoId 272\n",
      "Rank 108: AlunoId 478\n",
      "Rank 109: AlunoId 470\n",
      "Rank 110: AlunoId 583\n",
      "Rank 111: AlunoId 345\n",
      "Rank 112: AlunoId 489\n",
      "Rank 113: AlunoId 562\n",
      "Rank 114: AlunoId 664\n",
      "Rank 115: AlunoId 139\n",
      "Rank 116: AlunoId 393\n",
      "Rank 117: AlunoId 799\n",
      "Rank 118: AlunoId 65\n",
      "Rank 119: AlunoId 244\n",
      "Rank 120: AlunoId 689\n",
      "Rank 121: AlunoId 640\n",
      "Rank 122: AlunoId 232\n",
      "Rank 123: AlunoId 390\n",
      "Rank 124: AlunoId 395\n",
      "Rank 125: AlunoId 387\n",
      "Rank 126: AlunoId 192\n",
      "Rank 127: AlunoId 144\n",
      "Rank 128: AlunoId 145\n",
      "Rank 129: AlunoId 754\n",
      "Rank 130: AlunoId 727\n",
      "Rank 131: AlunoId 381\n",
      "Rank 132: AlunoId 231\n",
      "Rank 133: AlunoId 840\n",
      "Rank 134: AlunoId 105\n",
      "Rank 135: AlunoId 475\n",
      "Rank 136: AlunoId 224\n",
      "Rank 137: AlunoId 514\n",
      "Rank 138: AlunoId 207\n",
      "Rank 139: AlunoId 813\n",
      "Rank 140: AlunoId 344\n",
      "Rank 141: AlunoId 464\n",
      "Rank 142: AlunoId 550\n",
      "Rank 143: AlunoId 410\n",
      "Rank 144: AlunoId 671\n",
      "Rank 145: AlunoId 667\n",
      "Rank 146: AlunoId 35\n",
      "Rank 147: AlunoId 501\n",
      "Rank 148: AlunoId 822\n",
      "Rank 149: AlunoId 235\n",
      "Rank 150: AlunoId 293\n",
      "Rank 151: AlunoId 30\n",
      "Rank 152: AlunoId 68\n",
      "Rank 153: AlunoId 119\n",
      "Rank 154: AlunoId 729\n",
      "Rank 155: AlunoId 29\n",
      "Rank 156: AlunoId 824\n",
      "Rank 157: AlunoId 418\n",
      "Rank 158: AlunoId 766\n",
      "Rank 159: AlunoId 510\n",
      "Rank 160: AlunoId 553\n",
      "Rank 161: AlunoId 752\n",
      "Rank 162: AlunoId 377\n",
      "Rank 163: AlunoId 111\n",
      "Rank 164: AlunoId 124\n",
      "Rank 165: AlunoId 359\n",
      "Rank 166: AlunoId 323\n",
      "Rank 167: AlunoId 265\n",
      "Rank 168: AlunoId 220\n",
      "Rank 169: AlunoId 18\n",
      "Rank 170: AlunoId 637\n",
      "Rank 171: AlunoId 731\n",
      "Rank 172: AlunoId 465\n",
      "Rank 173: AlunoId 52\n",
      "Rank 174: AlunoId 405\n",
      "Rank 175: AlunoId 697\n",
      "Rank 176: AlunoId 242\n",
      "Rank 177: AlunoId 25\n",
      "Rank 178: AlunoId 379\n",
      "Rank 179: AlunoId 504\n",
      "Rank 180: AlunoId 78\n",
      "Rank 181: AlunoId 832\n",
      "Rank 182: AlunoId 44\n",
      "Rank 183: AlunoId 343\n",
      "Rank 184: AlunoId 181\n",
      "Rank 185: AlunoId 559\n",
      "Rank 186: AlunoId 412\n",
      "Rank 187: AlunoId 367\n",
      "Rank 188: AlunoId 332\n",
      "Rank 189: AlunoId 785\n",
      "Rank 190: AlunoId 150\n",
      "Rank 191: AlunoId 811\n",
      "Rank 192: AlunoId 439\n",
      "Rank 193: AlunoId 746\n",
      "Rank 194: AlunoId 763\n",
      "Rank 195: AlunoId 792\n",
      "Rank 196: AlunoId 765\n",
      "Rank 197: AlunoId 810\n",
      "Rank 198: AlunoId 375\n",
      "Rank 199: AlunoId 37\n",
      "Rank 200: AlunoId 818\n",
      "Rank 201: AlunoId 12\n",
      "Rank 202: AlunoId 374\n",
      "Rank 203: AlunoId 499\n",
      "Rank 204: AlunoId 97\n",
      "Rank 205: AlunoId 340\n",
      "Rank 206: AlunoId 738\n",
      "Rank 207: AlunoId 394\n",
      "Rank 208: AlunoId 677\n",
      "Rank 209: AlunoId 185\n",
      "Rank 210: AlunoId 582\n",
      "Rank 211: AlunoId 648\n",
      "Rank 212: AlunoId 406\n",
      "Rank 213: AlunoId 321\n",
      "Rank 214: AlunoId 309\n",
      "Rank 215: AlunoId 700\n",
      "Rank 216: AlunoId 115\n",
      "Rank 217: AlunoId 256\n",
      "Rank 218: AlunoId 373\n",
      "Rank 219: AlunoId 194\n",
      "Rank 220: AlunoId 803\n",
      "Rank 221: AlunoId 82\n",
      "Rank 222: AlunoId 378\n",
      "Rank 223: AlunoId 443\n",
      "Rank 224: AlunoId 370\n",
      "Rank 225: AlunoId 780\n",
      "Rank 226: AlunoId 229\n",
      "Rank 227: AlunoId 243\n",
      "Rank 228: AlunoId 346\n",
      "Rank 229: AlunoId 209\n",
      "Rank 230: AlunoId 154\n",
      "Rank 231: AlunoId 233\n",
      "Rank 232: AlunoId 302\n",
      "Rank 233: AlunoId 388\n",
      "Rank 234: AlunoId 360\n",
      "Rank 235: AlunoId 140\n",
      "Rank 236: AlunoId 551\n",
      "Rank 237: AlunoId 226\n",
      "Rank 238: AlunoId 403\n",
      "Rank 239: AlunoId 317\n",
      "Rank 240: AlunoId 330\n",
      "Rank 241: AlunoId 215\n",
      "Rank 242: AlunoId 589\n",
      "Rank 243: AlunoId 347\n",
      "Rank 244: AlunoId 283\n",
      "Rank 245: AlunoId 404\n",
      "Rank 246: AlunoId 401\n",
      "Rank 247: AlunoId 845\n",
      "Rank 248: AlunoId 741\n",
      "Rank 249: AlunoId 252\n",
      "Rank 250: AlunoId 807\n",
      "Rank 251: AlunoId 805\n",
      "Rank 252: AlunoId 2\n",
      "Rank 253: AlunoId 81\n",
      "Rank 254: AlunoId 228\n",
      "Rank 255: AlunoId 541\n",
      "Rank 256: AlunoId 247\n",
      "Rank 257: AlunoId 173\n",
      "Rank 258: AlunoId 164\n",
      "Rank 259: AlunoId 241\n",
      "Rank 260: AlunoId 93\n",
      "Rank 261: AlunoId 632\n",
      "Rank 262: AlunoId 442\n",
      "Rank 263: AlunoId 435\n",
      "Rank 264: AlunoId 421\n",
      "Rank 265: AlunoId 191\n",
      "Rank 266: AlunoId 564\n",
      "Rank 267: AlunoId 495\n",
      "Rank 268: AlunoId 268\n",
      "Rank 269: AlunoId 159\n",
      "Rank 270: AlunoId 523\n",
      "Rank 271: AlunoId 319\n",
      "Rank 272: AlunoId 182\n",
      "Rank 273: AlunoId 696\n",
      "Rank 274: AlunoId 42\n",
      "Rank 275: AlunoId 681\n",
      "Rank 276: AlunoId 833\n",
      "Rank 277: AlunoId 165\n",
      "Rank 278: AlunoId 138\n",
      "Rank 279: AlunoId 606\n",
      "Rank 280: AlunoId 471\n",
      "Rank 281: AlunoId 161\n",
      "Rank 282: AlunoId 262\n",
      "Rank 283: AlunoId 263\n",
      "Rank 284: AlunoId 88\n",
      "Rank 285: AlunoId 9\n",
      "Rank 286: AlunoId 110\n",
      "Rank 287: AlunoId 142\n",
      "Rank 288: AlunoId 424\n",
      "Rank 289: AlunoId 254\n",
      "Rank 290: AlunoId 502\n",
      "Rank 291: AlunoId 179\n",
      "Rank 292: AlunoId 239\n",
      "Rank 293: AlunoId 58\n",
      "Rank 294: AlunoId 189\n",
      "Rank 295: AlunoId 325\n",
      "Rank 296: AlunoId 4\n",
      "Rank 297: AlunoId 289\n",
      "Rank 298: AlunoId 32\n",
      "Rank 299: AlunoId 116\n",
      "Rank 300: AlunoId 60\n",
      "Rank 301: AlunoId 210\n",
      "Rank 302: AlunoId 474\n",
      "Rank 303: AlunoId 257\n",
      "Rank 304: AlunoId 663\n",
      "Rank 305: AlunoId 203\n",
      "Rank 306: AlunoId 234\n",
      "Rank 307: AlunoId 275\n",
      "Rank 308: AlunoId 419\n",
      "Rank 309: AlunoId 118\n",
      "Rank 310: AlunoId 826\n",
      "Rank 311: AlunoId 240\n",
      "Rank 312: AlunoId 581\n",
      "Rank 313: AlunoId 255\n",
      "Rank 314: AlunoId 131\n",
      "Rank 315: AlunoId 314\n",
      "Rank 316: AlunoId 75\n",
      "Rank 317: AlunoId 603\n",
      "Rank 318: AlunoId 820\n",
      "Rank 319: AlunoId 277\n",
      "Rank 320: AlunoId 599\n",
      "Rank 321: AlunoId 21\n",
      "Rank 322: AlunoId 196\n",
      "Rank 323: AlunoId 211\n",
      "Rank 324: AlunoId 536\n",
      "Rank 325: AlunoId 49\n",
      "Rank 326: AlunoId 616\n",
      "Rank 327: AlunoId 311\n",
      "Rank 328: AlunoId 204\n",
      "Rank 329: AlunoId 83\n",
      "Rank 330: AlunoId 733\n",
      "Rank 331: AlunoId 730\n",
      "Rank 332: AlunoId 392\n",
      "Rank 333: AlunoId 645\n",
      "Rank 334: AlunoId 366\n",
      "Rank 335: AlunoId 108\n",
      "Rank 336: AlunoId 291\n",
      "Rank 337: AlunoId 430\n",
      "Rank 338: AlunoId 213\n",
      "Rank 339: AlunoId 3\n",
      "Rank 340: AlunoId 267\n",
      "Rank 341: AlunoId 482\n",
      "Rank 342: AlunoId 349\n",
      "Rank 343: AlunoId 227\n",
      "Rank 344: AlunoId 525\n",
      "Rank 345: AlunoId 498\n",
      "Rank 346: AlunoId 175\n",
      "Rank 347: AlunoId 313\n",
      "Rank 348: AlunoId 66\n",
      "Rank 349: AlunoId 828\n",
      "Rank 350: AlunoId 218\n",
      "Rank 351: AlunoId 200\n",
      "Rank 352: AlunoId 16\n",
      "Rank 353: AlunoId 279\n",
      "Rank 354: AlunoId 675\n",
      "Rank 355: AlunoId 264\n",
      "Rank 356: AlunoId 560\n",
      "Rank 357: AlunoId 368\n",
      "Rank 358: AlunoId 685\n",
      "Rank 359: AlunoId 98\n",
      "Rank 360: AlunoId 261\n",
      "Rank 361: AlunoId 86\n",
      "Rank 362: AlunoId 103\n",
      "Rank 363: AlunoId 750\n",
      "Rank 364: AlunoId 631\n",
      "Rank 365: AlunoId 571\n",
      "Rank 366: AlunoId 391\n",
      "Rank 367: AlunoId 526\n",
      "Rank 368: AlunoId 72\n",
      "Rank 369: AlunoId 445\n",
      "Rank 370: AlunoId 670\n",
      "Rank 371: AlunoId 335\n",
      "Rank 372: AlunoId 376\n",
      "Rank 373: AlunoId 354\n",
      "Rank 374: AlunoId 130\n",
      "Rank 375: AlunoId 148\n",
      "Rank 376: AlunoId 85\n",
      "Rank 377: AlunoId 266\n",
      "Rank 378: AlunoId 129\n",
      "Rank 379: AlunoId 312\n",
      "Rank 380: AlunoId 701\n",
      "Rank 381: AlunoId 13\n",
      "Rank 382: AlunoId 141\n",
      "Rank 383: AlunoId 622\n",
      "Rank 384: AlunoId 27\n",
      "Rank 385: AlunoId 841\n",
      "Rank 386: AlunoId 428\n",
      "Rank 387: AlunoId 469\n",
      "Rank 388: AlunoId 24\n",
      "Rank 389: AlunoId 162\n",
      "Rank 390: AlunoId 547\n",
      "Rank 391: AlunoId 533\n",
      "Rank 392: AlunoId 48\n",
      "Rank 393: AlunoId 764\n",
      "Rank 394: AlunoId 638\n",
      "Rank 395: AlunoId 643\n",
      "Rank 396: AlunoId 47\n",
      "Rank 397: AlunoId 422\n",
      "Rank 398: AlunoId 318\n",
      "Rank 399: AlunoId 186\n",
      "Rank 400: AlunoId 158\n",
      "Rank 401: AlunoId 246\n",
      "Rank 402: AlunoId 216\n",
      "Rank 403: AlunoId 183\n",
      "Rank 404: AlunoId 506\n",
      "Rank 405: AlunoId 684\n",
      "Rank 406: AlunoId 775\n",
      "Rank 407: AlunoId 7\n",
      "Rank 408: AlunoId 301\n",
      "Rank 409: AlunoId 618\n",
      "Rank 410: AlunoId 710\n",
      "Rank 411: AlunoId 420\n",
      "Rank 412: AlunoId 613\n",
      "Rank 413: AlunoId 717\n",
      "Rank 414: AlunoId 43\n",
      "Rank 415: AlunoId 369\n",
      "Rank 416: AlunoId 127\n",
      "Rank 417: AlunoId 337\n",
      "Rank 418: AlunoId 1\n",
      "Rank 419: AlunoId 567\n",
      "Rank 420: AlunoId 755\n",
      "Rank 421: AlunoId 34\n",
      "Rank 422: AlunoId 702\n",
      "Rank 423: AlunoId 777\n",
      "Rank 424: AlunoId 633\n",
      "Rank 425: AlunoId 195\n",
      "Rank 426: AlunoId 601\n",
      "Rank 427: AlunoId 26\n",
      "Rank 428: AlunoId 714\n",
      "Rank 429: AlunoId 720\n",
      "Rank 430: AlunoId 715\n",
      "Rank 431: AlunoId 767\n",
      "Rank 432: AlunoId 612\n",
      "Rank 433: AlunoId 508\n",
      "Rank 434: AlunoId 476\n",
      "Rank 435: AlunoId 772\n",
      "Rank 436: AlunoId 509\n",
      "Rank 437: AlunoId 397\n",
      "Rank 438: AlunoId 166\n",
      "Rank 439: AlunoId 106\n",
      "Rank 440: AlunoId 781\n",
      "Rank 441: AlunoId 758\n",
      "Rank 442: AlunoId 176\n",
      "Rank 443: AlunoId 461\n",
      "Rank 444: AlunoId 100\n",
      "Rank 445: AlunoId 96\n",
      "Rank 446: AlunoId 306\n",
      "Rank 447: AlunoId 117\n",
      "Rank 448: AlunoId 136\n",
      "Rank 449: AlunoId 126\n",
      "Rank 450: AlunoId 14\n",
      "Rank 451: AlunoId 768\n",
      "Rank 452: AlunoId 398\n",
      "Rank 453: AlunoId 770\n",
      "Rank 454: AlunoId 529\n",
      "Rank 455: AlunoId 63\n",
      "Rank 456: AlunoId 485\n",
      "Rank 457: AlunoId 69\n",
      "Rank 458: AlunoId 371\n",
      "Rank 459: AlunoId 527\n",
      "Rank 460: AlunoId 706\n",
      "Rank 461: AlunoId 580\n",
      "Rank 462: AlunoId 222\n",
      "Rank 463: AlunoId 135\n",
      "Rank 464: AlunoId 74\n",
      "Rank 465: AlunoId 296\n",
      "Rank 466: AlunoId 707\n",
      "Rank 467: AlunoId 206\n",
      "Rank 468: AlunoId 457\n",
      "Rank 469: AlunoId 479\n",
      "Rank 470: AlunoId 521\n",
      "Rank 471: AlunoId 463\n",
      "Rank 472: AlunoId 779\n",
      "Rank 473: AlunoId 448\n",
      "Rank 474: AlunoId 705\n",
      "Rank 475: AlunoId 152\n",
      "Rank 476: AlunoId 691\n",
      "Rank 477: AlunoId 623\n",
      "Rank 478: AlunoId 709\n",
      "Rank 479: AlunoId 326\n",
      "Rank 480: AlunoId 123\n",
      "Rank 481: AlunoId 423\n",
      "Rank 482: AlunoId 451\n",
      "Rank 483: AlunoId 532\n",
      "Rank 484: AlunoId 732\n",
      "Rank 485: AlunoId 673\n",
      "Rank 486: AlunoId 745\n",
      "Rank 487: AlunoId 716\n",
      "Rank 488: AlunoId 695\n",
      "Rank 489: AlunoId 316\n",
      "Rank 490: AlunoId 665\n",
      "Rank 491: AlunoId 751\n",
      "Rank 492: AlunoId 769\n",
      "Rank 493: AlunoId 724\n",
      "Rank 494: AlunoId 55\n",
      "Rank 495: AlunoId 739\n",
      "Rank 496: AlunoId 723\n",
      "Rank 497: AlunoId 102\n",
      "Rank 498: AlunoId 507\n",
      "Rank 499: AlunoId 341\n",
      "Rank 500: AlunoId 786\n",
      "Rank 501: AlunoId 460\n",
      "Rank 502: AlunoId 782\n",
      "Rank 503: AlunoId 574\n",
      "Rank 504: AlunoId 586\n",
      "Rank 505: AlunoId 180\n",
      "Rank 506: AlunoId 28\n",
      "Rank 507: AlunoId 815\n",
      "Rank 508: AlunoId 54\n",
      "Rank 509: AlunoId 778\n",
      "Rank 510: AlunoId 791\n",
      "Rank 511: AlunoId 759\n",
      "Rank 512: AlunoId 761\n",
      "Rank 513: AlunoId 351\n",
      "Rank 514: AlunoId 661\n",
      "Rank 515: AlunoId 608\n",
      "Rank 516: AlunoId 516\n",
      "Rank 517: AlunoId 38\n",
      "Rank 518: AlunoId 193\n",
      "Rank 519: AlunoId 303\n",
      "Rank 520: AlunoId 458\n",
      "Rank 521: AlunoId 816\n",
      "Rank 522: AlunoId 821\n",
      "Rank 523: AlunoId 690\n",
      "Rank 524: AlunoId 740\n",
      "Rank 525: AlunoId 719\n",
      "Rank 526: AlunoId 426\n",
      "Rank 527: AlunoId 447\n",
      "Rank 528: AlunoId 809\n",
      "Rank 529: AlunoId 825\n",
      "Rank 530: AlunoId 433\n",
      "Rank 531: AlunoId 518\n",
      "Rank 532: AlunoId 812\n",
      "Rank 533: AlunoId 549\n",
      "Rank 534: AlunoId 307\n",
      "Rank 535: AlunoId 253\n",
      "Rank 536: AlunoId 230\n",
      "Rank 537: AlunoId 565\n",
      "Rank 538: AlunoId 178\n",
      "Rank 539: AlunoId 101\n",
      "Rank 540: AlunoId 660\n",
      "Rank 541: AlunoId 546\n",
      "Rank 542: AlunoId 36\n",
      "Rank 543: AlunoId 519\n",
      "Rank 544: AlunoId 177\n",
      "Rank 545: AlunoId 597\n",
      "Rank 546: AlunoId 417\n",
      "Rank 547: AlunoId 686\n",
      "Rank 548: AlunoId 441\n",
      "Rank 549: AlunoId 315\n",
      "Rank 550: AlunoId 511\n",
      "Rank 551: AlunoId 168\n",
      "Rank 552: AlunoId 90\n",
      "Rank 553: AlunoId 646\n",
      "Rank 554: AlunoId 656\n",
      "Rank 555: AlunoId 198\n",
      "Rank 556: AlunoId 208\n",
      "Rank 557: AlunoId 15\n",
      "Rank 558: AlunoId 271\n",
      "Rank 559: AlunoId 19\n",
      "Rank 560: AlunoId 704\n",
      "Rank 561: AlunoId 31\n",
      "Rank 562: AlunoId 619\n",
      "Rank 563: AlunoId 662\n",
      "Rank 564: AlunoId 483\n",
      "Rank 565: AlunoId 87\n",
      "Rank 566: AlunoId 647\n",
      "Rank 567: AlunoId 327\n",
      "Rank 568: AlunoId 512\n",
      "Rank 569: AlunoId 528\n",
      "Rank 570: AlunoId 107\n",
      "Rank 571: AlunoId 450\n",
      "Rank 572: AlunoId 56\n",
      "Rank 573: AlunoId 626\n",
      "Rank 574: AlunoId 328\n",
      "Rank 575: AlunoId 104\n",
      "Rank 576: AlunoId 604\n",
      "Rank 577: AlunoId 6\n",
      "Rank 578: AlunoId 459\n",
      "Rank 579: AlunoId 666\n",
      "Rank 580: AlunoId 682\n",
      "Rank 581: AlunoId 517\n",
      "Rank 582: AlunoId 122\n",
      "Rank 583: AlunoId 219\n",
      "Rank 584: AlunoId 687\n",
      "Rank 585: AlunoId 595\n",
      "Rank 586: AlunoId 639\n",
      "Rank 587: AlunoId 45\n",
      "Rank 588: AlunoId 160\n",
      "Rank 589: AlunoId 713\n",
      "Rank 590: AlunoId 362\n",
      "Rank 591: AlunoId 46\n",
      "Rank 592: AlunoId 77\n",
      "Rank 593: AlunoId 554\n",
      "Rank 594: AlunoId 120\n",
      "Rank 595: AlunoId 587\n",
      "Rank 596: AlunoId 760\n",
      "Rank 597: AlunoId 784\n",
      "Rank 598: AlunoId 817\n",
      "Rank 599: AlunoId 73\n",
      "Rank 600: AlunoId 50\n",
      "Rank 601: AlunoId 432\n",
      "Rank 602: AlunoId 287\n",
      "Rank 603: AlunoId 688\n",
      "Rank 604: AlunoId 153\n",
      "Rank 605: AlunoId 151\n",
      "Rank 606: AlunoId 8\n",
      "Rank 607: AlunoId 570\n",
      "Rank 608: AlunoId 355\n",
      "Rank 609: AlunoId 524\n",
      "Rank 610: AlunoId 590\n",
      "Rank 611: AlunoId 20\n",
      "Rank 612: AlunoId 39\n",
      "Rank 613: AlunoId 839\n",
      "Rank 614: AlunoId 827\n",
      "Rank 615: AlunoId 831\n",
      "Rank 616: AlunoId 748\n",
      "Rank 617: AlunoId 735\n",
      "Rank 618: AlunoId 830\n",
      "Rank 619: AlunoId 409\n",
      "Rank 620: AlunoId 40\n",
      "Rank 621: AlunoId 364\n",
      "Rank 622: AlunoId 284\n",
      "Rank 623: AlunoId 537\n",
      "Rank 624: AlunoId 802\n",
      "Rank 625: AlunoId 310\n",
      "Rank 626: AlunoId 155\n",
      "Rank 627: AlunoId 187\n",
      "Rank 628: AlunoId 718\n",
      "Rank 629: AlunoId 572\n",
      "Rank 630: AlunoId 333\n",
      "Rank 631: AlunoId 157\n",
      "Rank 632: AlunoId 197\n",
      "Rank 633: AlunoId 672\n",
      "Rank 634: AlunoId 408\n",
      "Rank 635: AlunoId 804\n",
      "Rank 636: AlunoId 396\n",
      "Rank 637: AlunoId 415\n",
      "Rank 638: AlunoId 304\n",
      "Rank 639: AlunoId 629\n",
      "Rank 640: AlunoId 53\n",
      "Rank 641: AlunoId 653\n",
      "Rank 642: AlunoId 276\n",
      "Rank 643: AlunoId 286\n",
      "Rank 644: AlunoId 694\n",
      "Rank 645: AlunoId 575\n",
      "Rank 646: AlunoId 522\n",
      "Rank 647: AlunoId 438\n",
      "Rank 648: AlunoId 339\n",
      "Rank 649: AlunoId 669\n",
      "Rank 650: AlunoId 282\n",
      "Rank 651: AlunoId 680\n",
      "Rank 652: AlunoId 274\n",
      "Rank 653: AlunoId 137\n",
      "Rank 654: AlunoId 584\n",
      "Rank 655: AlunoId 425\n",
      "Rank 656: AlunoId 329\n",
      "Rank 657: AlunoId 99\n",
      "Rank 658: AlunoId 789\n",
      "Rank 659: AlunoId 416\n",
      "Rank 660: AlunoId 787\n",
      "Rank 661: AlunoId 184\n",
      "Rank 662: AlunoId 149\n",
      "Rank 663: AlunoId 414\n",
      "Rank 664: AlunoId 576\n",
      "Rank 665: AlunoId 535\n",
      "Rank 666: AlunoId 491\n",
      "Rank 667: AlunoId 548\n",
      "Rank 668: AlunoId 788\n",
      "Rank 669: AlunoId 801\n",
      "Rank 670: AlunoId 331\n",
      "Rank 671: AlunoId 288\n",
      "Rank 672: AlunoId 41\n",
      "Rank 673: AlunoId 169\n",
      "Rank 674: AlunoId 484\n",
      "Rank 675: AlunoId 440\n",
      "Rank 676: AlunoId 642\n",
      "Rank 677: AlunoId 67\n",
      "Rank 678: AlunoId 121\n",
      "Rank 679: AlunoId 600\n",
      "Rank 680: AlunoId 172\n",
      "Rank 681: AlunoId 94\n",
      "Rank 682: AlunoId 683\n",
      "Rank 683: AlunoId 652\n",
      "Rank 684: AlunoId 190\n",
      "Rank 685: AlunoId 534\n",
      "Rank 686: AlunoId 305\n",
      "Rank 687: AlunoId 794\n",
      "Rank 688: AlunoId 679\n",
      "Rank 689: AlunoId 352\n",
      "Rank 690: AlunoId 625\n",
      "Rank 691: AlunoId 386\n",
      "Rank 692: AlunoId 462\n",
      "Rank 693: AlunoId 480\n",
      "Rank 694: AlunoId 236\n",
      "Rank 695: AlunoId 308\n",
      "Rank 696: AlunoId 92\n",
      "Rank 697: AlunoId 558\n",
      "Rank 698: AlunoId 776\n",
      "Rank 699: AlunoId 614\n",
      "Rank 700: AlunoId 531\n",
      "Rank 701: AlunoId 722\n",
      "Rank 702: AlunoId 221\n",
      "Rank 703: AlunoId 5\n",
      "Rank 704: AlunoId 555\n",
      "Rank 705: AlunoId 125\n",
      "Rank 706: AlunoId 596\n",
      "Rank 707: AlunoId 380\n",
      "Rank 708: AlunoId 563\n",
      "Rank 709: AlunoId 557\n",
      "Rank 710: AlunoId 205\n",
      "Rank 711: AlunoId 322\n",
      "Rank 712: AlunoId 133\n",
      "Rank 713: AlunoId 615\n",
      "Rank 714: AlunoId 774\n",
      "Rank 715: AlunoId 11\n",
      "Rank 716: AlunoId 636\n",
      "Rank 717: AlunoId 650\n",
      "Rank 718: AlunoId 320\n",
      "Rank 719: AlunoId 649\n",
      "Rank 720: AlunoId 538\n",
      "Rank 721: AlunoId 610\n",
      "Rank 722: AlunoId 515\n",
      "Rank 723: AlunoId 585\n",
      "Rank 724: AlunoId 834\n",
      "Rank 725: AlunoId 790\n",
      "Rank 726: AlunoId 678\n",
      "Rank 727: AlunoId 290\n",
      "Rank 728: AlunoId 644\n",
      "Rank 729: AlunoId 431\n",
      "Rank 730: AlunoId 22\n",
      "Rank 731: AlunoId 472\n",
      "Rank 732: AlunoId 793\n",
      "Rank 733: AlunoId 427\n",
      "Rank 734: AlunoId 297\n",
      "Rank 735: AlunoId 674\n",
      "Rank 736: AlunoId 299\n",
      "Rank 737: AlunoId 237\n",
      "Rank 738: AlunoId 434\n",
      "Rank 739: AlunoId 711\n",
      "Rank 740: AlunoId 843\n",
      "Rank 741: AlunoId 51\n",
      "Rank 742: AlunoId 487\n",
      "Rank 743: AlunoId 747\n",
      "Rank 744: AlunoId 728\n",
      "Rank 745: AlunoId 692\n",
      "Rank 746: AlunoId 147\n",
      "Rank 747: AlunoId 594\n",
      "Rank 748: AlunoId 455\n",
      "Rank 749: AlunoId 156\n",
      "Rank 750: AlunoId 783\n",
      "Rank 751: AlunoId 744\n",
      "Rank 752: AlunoId 273\n",
      "Rank 753: AlunoId 174\n",
      "Rank 754: AlunoId 481\n",
      "Rank 755: AlunoId 726\n",
      "Rank 756: AlunoId 217\n",
      "Rank 757: AlunoId 712\n",
      "Rank 758: AlunoId 798\n",
      "Rank 759: AlunoId 294\n",
      "Rank 760: AlunoId 635\n",
      "Rank 761: AlunoId 598\n",
      "Rank 762: AlunoId 844\n",
      "Rank 763: AlunoId 593\n",
      "Rank 764: AlunoId 413\n",
      "Rank 765: AlunoId 300\n",
      "Rank 766: AlunoId 225\n",
      "Rank 767: AlunoId 10\n",
      "Rank 768: AlunoId 324\n",
      "Rank 769: AlunoId 477\n",
      "Rank 770: AlunoId 429\n",
      "Rank 771: AlunoId 628\n",
      "Rank 772: AlunoId 556\n",
      "Rank 773: AlunoId 214\n",
      "Rank 774: AlunoId 202\n",
      "Rank 775: AlunoId 577\n",
      "Rank 776: AlunoId 676\n",
      "Rank 777: AlunoId 285\n",
      "Rank 778: AlunoId 411\n",
      "Rank 779: AlunoId 146\n",
      "Rank 780: AlunoId 238\n",
      "Rank 781: AlunoId 486\n",
      "Rank 782: AlunoId 295\n",
      "Rank 783: AlunoId 80\n",
      "Rank 784: AlunoId 201\n",
      "Rank 785: AlunoId 753\n",
      "Rank 786: AlunoId 771\n",
      "Rank 787: AlunoId 95\n",
      "Rank 788: AlunoId 579\n",
      "Rank 789: AlunoId 245\n",
      "Rank 790: AlunoId 756\n",
      "Rank 791: AlunoId 269\n",
      "Rank 792: AlunoId 260\n",
      "Rank 793: AlunoId 627\n",
      "Rank 794: AlunoId 578\n",
      "Rank 795: AlunoId 223\n",
      "Rank 796: AlunoId 70\n",
      "Rank 797: AlunoId 591\n",
      "Rank 798: AlunoId 569\n",
      "Rank 799: AlunoId 658\n",
      "Rank 800: AlunoId 400\n",
      "Rank 801: AlunoId 490\n",
      "Rank 802: AlunoId 89\n",
      "Rank 803: AlunoId 134\n",
      "Rank 804: AlunoId 624\n",
      "Rank 805: AlunoId 79\n",
      "Rank 806: AlunoId 592\n",
      "Rank 807: AlunoId 372\n",
      "Rank 808: AlunoId 573\n",
      "Rank 809: AlunoId 251\n",
      "Rank 810: AlunoId 566\n",
      "Rank 811: AlunoId 630\n",
      "Rank 812: AlunoId 737\n",
      "Rank 813: AlunoId 466\n",
      "Rank 814: AlunoId 693\n",
      "Rank 815: AlunoId 621\n",
      "Rank 816: AlunoId 634\n",
      "Rank 817: AlunoId 617\n",
      "Rank 818: AlunoId 607\n",
      "Rank 819: AlunoId 132\n",
      "Rank 820: AlunoId 62\n",
      "Rank 821: AlunoId 76\n",
      "Rank 822: AlunoId 698\n",
      "Rank 823: AlunoId 611\n",
      "Rank 824: AlunoId 71\n",
      "Rank 825: AlunoId 212\n",
      "Rank 826: AlunoId 659\n",
      "Rank 827: AlunoId 602\n",
      "Rank 828: AlunoId 57\n",
      "Rank 829: AlunoId 609\n",
      "Rank 830: AlunoId 407\n",
      "Rank 831: AlunoId 655\n",
      "Rank 832: AlunoId 654\n",
      "Rank 833: AlunoId 819\n",
      "Rank 834: AlunoId 59\n",
      "Rank 835: AlunoId 795\n",
      "Rank 836: AlunoId 91\n",
      "Rank 837: AlunoId 742\n",
      "Rank 838: AlunoId 641\n",
      "Rank 839: AlunoId 568\n",
      "Rank 840: AlunoId 84\n",
      "Rank 841: AlunoId 199\n",
      "Rank 842: AlunoId 64\n",
      "Rank 843: AlunoId 651\n",
      "Rank 844: AlunoId 61\n",
      "Rank 845: AlunoId 743\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Step 9: Rank the alternatives based on the relative closeness\n",
    "ranked_indices = np.argsort(closeness)[::-1]  # Sort in descending order\n",
    "\n",
    "# Step 10: Print the ranked alternatives\n",
    "for i, idx in enumerate(ranked_indices):\n",
    "    print(f\"Rank {i+1}: AlunoId {idx+1}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Nota Pt., Nota Mat., Autoaval., Notas, Envol.Score]\n",
      "[ 2.  2.  2.  1. 12.  0.]\n",
      "[ 2.  2.  2.  1. 16.  0.]\n",
      "[ 2.  2.  1.  1. 18.  0.]\n",
      "[ 2.  2.  2.  1. 17.  0.]\n",
      "[ 2.  2.  2.  1. 18.  0.]\n",
      "[ 2.  2.  2.  1. 18.  0.]\n",
      "[ 2.  2.  3.  1. 17.  0.]\n",
      "\n",
      "Ultimas ranks - Alunos Baixo Risco\n",
      "[ 5.  5.  5.  5. 25.  3.]\n",
      "[ 5.  5.  5.  5. 25.  3.]\n",
      "[ 5.  5.  5.  5. 25.  3.]\n",
      "[ 5.  5.  5.  5. 25.  3.]\n"
     ]
    }
   ],
   "source": [
    "print(\"[Nota Pt., Nota Mat., Autoaval., Notas, Envol.Score]\")\n",
    "print(dataset_final.iloc[495,:].values)\n",
    "print(dataset_final.iloc[247,:].values)\n",
    "print(dataset_final.iloc[258,:].values)\n",
    "print(dataset_final.iloc[112,:].values)\n",
    "print(dataset_final.iloc[491,:].values)\n",
    "print(dataset_final.iloc[799,:].values)\n",
    "print(dataset_final.iloc[111,:].values)\n",
    "\n",
    "print(\"\\nUltimas ranks - Alunos Baixo Risco\")\n",
    "print(dataset_final.iloc[63,:].values)\n",
    "print(dataset_final.iloc[650,:].values)\n",
    "print(dataset_final.iloc[60,:].values)\n",
    "print(dataset_final.iloc[742,:].values)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Tese",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
